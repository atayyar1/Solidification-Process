{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QyIKhz8FNth"
      },
      "source": [
        "##**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VYytvocoKuQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "e0fc032c-b2e6-438b-bfbb-9c99e70439d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pycuda'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-480340873.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import pycuda.driver as drv\n",
        "import pycuda.gpuarray as gpuarray\n",
        "\n",
        "from pycuda.compiler import SourceModule"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnvCxghSBjEC",
        "outputId": "9dcc7118-08db-4820-e9dc-b9015a19bf05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2025.1.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.2.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.8)\n",
            "Requirement already satisfied: mako in /usr/lib/python3/dist-packages (from pycuda) (1.1.3)\n",
            "Collecting siphash24>=1.6 (from pytools>=2011.2->pycuda)\n",
            "  Downloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.14.1)\n",
            "Downloading pytools-2025.2.2-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading siphash24-1.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2025.1.1-cp311-cp311-linux_x86_64.whl size=660712 sha256=68e4b0ea9ddda38a929b573ab93ab1592af3a067d22c96e0ce5beb9995eeebff\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/0a/64/6530a5fde64f984ebb4992e38744fdfd2a61f510377b3a24d9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: siphash24, pytools, pycuda\n",
            "Successfully installed pycuda-2025.1.1 pytools-2025.2.2 siphash24-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NeZ8izwFXJg"
      },
      "source": [
        "## **Get information of GPU connected**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mbk0EG0IgBy",
        "outputId": "413511b3-a05b-4b2f-d62a-f7aa45b31528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  8 17:47:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0             28W /   70W |     126MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OSylXe9FQ6J"
      },
      "source": [
        "##**Set parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVaSW6lILOdj"
      },
      "outputs": [],
      "source": [
        "# --- Spatial & temporal discretization ---\n",
        "dx = dy = 0.025\n",
        "nx = ny = 500\n",
        "\n",
        "dt      = 5e-8      # from FiPy example\n",
        "stepmax = 10000     # match FiPy’s 10 000 steps\n",
        "\n",
        "# --- Physical coefficients ---\n",
        "tau    = 3e-4       # relaxation time\n",
        "kappa  = 2.25       # thermal diffusivity\n",
        "\n",
        "# --- Anisotropy (6‐fold) ---\n",
        "zeta   = 0.02       # anisotropy strength\n",
        "aniso  = 6.0        # symmetry order\n",
        "angle0 = np.pi/8    # orientation\n",
        "\n",
        "# --- Temperature‐coupling ---\n",
        "kappa1 = 0.9\n",
        "kappa2 = 20.0\n",
        "\n",
        "# --- Seed & interface ---\n",
        "r0    = 5 * dx      # radius = 5 cells\n",
        "width = dx          # diffuse‐interface ≈ 1 cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96PBzr1aFjPE"
      },
      "source": [
        "##**Define arrays in Host (CPU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuwyzZtZLO1J"
      },
      "outputs": [],
      "source": [
        "phi_host = np.zeros((nx,ny))\n",
        "phi_new_host = np.zeros((nx,ny))\n",
        "temp_host = np.zeros((nx,ny))\n",
        "temp_new_host = np.zeros((nx,ny))\n",
        "grad_phix_host = np.zeros((nx,ny))\n",
        "grad_phiy_host = np.zeros((nx,ny))\n",
        "a2_host = np.zeros((nx,ny))\n",
        "lap_temp_host = np.zeros((nx,ny))\n",
        "lap_phi_host = np.zeros((nx,ny))\n",
        "ax_host = np.zeros((nx,ny))\n",
        "ay_host = np.zeros((nx,ny))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLgFq4KDF2TQ"
      },
      "source": [
        "## **Set initial distributions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFD6pg3bLeUM"
      },
      "outputs": [],
      "source": [
        "# — Initialization in dimensionless units —\n",
        "\n",
        "# Allocate & zero\n",
        "phi_host  = np.zeros((nx,ny), dtype=np.float64)\n",
        "temp_host = np.zeros((nx,ny), dtype=np.float64)\n",
        "\n",
        "# Initialize a smooth circle of φ and matching temperature θ = –φ\n",
        "for j in range(ny):\n",
        "    y = (j/ny) - 0.5\n",
        "    for i in range(nx):\n",
        "        x = (i/nx) - 0.5\n",
        "        r = np.hypot(x, y)\n",
        "        phi_val = 0.5*(1.0 - np.tanh((r-r0)/width))\n",
        "        phi_host[i,j]  = phi_val\n",
        "        temp_host[i,j] = -0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ek9c0YjFJJ9"
      },
      "source": [
        "## **Define \"Device code\" to calculate gradient of phi and temp and interfacial anisotropy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6IcZT1bLQU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60db2cf-7c30-4479-febc-5947714652ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled calcgrad: <pycuda._driver.Function object at 0x7abcc8d33740>\n"
          ]
        }
      ],
      "source": [
        "def get_kernel_string1_nd(nx, ny, dx, dy, pi, zeta, aniso, angle0):\n",
        "    kernel = \"\"\"\n",
        "    #include <math.h>\n",
        "    #define nx {nx}\n",
        "    #define ny {ny}\n",
        "    #define dx {dx:.6e}\n",
        "    #define dy {dy:.6e}\n",
        "    #define pi  {pi}\n",
        "    #define zeta {zeta}\n",
        "    #define aniso {aniso}\n",
        "    #define angle0 {angle0}\n",
        "\n",
        "    __global__ void calcgrad(\n",
        "        const double *phi,\n",
        "        const double *temp,\n",
        "        double *grad_phix,\n",
        "        double *grad_phiy,\n",
        "        double *lap_phi,\n",
        "        double *lap_temp,\n",
        "        double *ax,\n",
        "        double *ay,\n",
        "        double *a2\n",
        "    ){{\n",
        "        int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "        if(i >= nx || j >= ny) return;\n",
        "        int ip = (i + 1) % nx, im = (i - 1 + nx) % nx;\n",
        "        int jp = (j + 1) % ny, jm = (j - 1 + ny) % ny;\n",
        "\n",
        "        int idx    = j*nx + i;\n",
        "        int idx_ip = j*nx + ip, idx_im = j*nx + im;\n",
        "        int idx_jp = jp*nx + i, idx_jm = jm*nx + i;\n",
        "\n",
        "        // gradients\n",
        "        grad_phix[idx] = (phi[idx_ip] - phi[idx_im]) / (2.0 * dx);\n",
        "        grad_phiy[idx] = (phi[idx_jp] - phi[idx_jm]) / (2.0 * dy);\n",
        "\n",
        "        // 9-point laplacian (dimensionless)\n",
        "        lap_phi[idx]  = (\n",
        "            2.0*(phi[idx_ip] + phi[idx_im] + phi[idx_jp] + phi[idx_jm]) +\n",
        "            phi[jp*nx+ip] + phi[jm*nx+im] + phi[jp*nx+im] + phi[jm*nx+ip] -\n",
        "            12.0*phi[idx]\n",
        "        ) / (3.0 * dx * dx);\n",
        "\n",
        "        lap_temp[idx] = (\n",
        "            2.0*(temp[idx_ip] + temp[idx_im] + temp[idx_jp] + temp[idx_jm]) +\n",
        "            temp[jp*nx+ip] + temp[jm*nx+im] + temp[jp*nx+im] + temp[jm*nx+ip] -\n",
        "            12.0*temp[idx]\n",
        "        ) / (3.0 * dx * dx);\n",
        "\n",
        "        // anisotropy angle ψ\n",
        "        double gx = grad_phix[idx], gy = grad_phiy[idx];\n",
        "        double ang;\n",
        "        if (gx == 0.0) {{\n",
        "            ang = (gy > 0.0) ? 0.5*pi : -0.5*pi;\n",
        "        }} else if (gx > 0.0) {{\n",
        "            ang = (gy >= 0.0) ? atan(gy/gx) : 2.0*pi + atan(gy/gx);\n",
        "        }} else {{\n",
        "            ang = pi + atan(gy/gx);\n",
        "        }}\n",
        "\n",
        "        // anisotropy strength a(ψ) and its derivative\n",
        "        double a = 1.0 + zeta * cos(aniso*(ang - angle0));\n",
        "        double da = -aniso*zeta * sin(aniso*(ang - angle0));\n",
        "\n",
        "        // store flux‐coefficients\n",
        "        ax[idx] =  a * da * gx;\n",
        "        ay[idx] = -a * da * gy;\n",
        "        a2[idx] =  a * a;\n",
        "    }}\n",
        "    \"\"\"\n",
        "    return kernel.format(\n",
        "        nx=nx, ny=ny,\n",
        "        dx=dx, dy=dy,\n",
        "        pi=pi, zeta=zeta,\n",
        "        aniso=aniso, angle0=angle0\n",
        "    )\n",
        "\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "# ensure block_size_string is defined\n",
        "block_size_string = \"#define block_size_x 16\\n#define block_size_y 16\\n\"\n",
        "\n",
        "# define π if not already\n",
        "pi = np.pi\n",
        "import pycuda.autoinit\n",
        "from pycuda import driver as drv\n",
        "device = drv.Context.get_current().get_device()\n",
        "major, minor = device.compute_capability()\n",
        "cc = f\"{major}{minor}\"\n",
        "# gcc out your kernel string\n",
        "kernel_string1 = get_kernel_string1_nd(\n",
        "    nx, ny,\n",
        "    dx, dy,\n",
        "    pi,\n",
        "    zeta,\n",
        "    aniso,\n",
        "    angle0\n",
        ")\n",
        "\n",
        "# compile\n",
        "mod = SourceModule(block_size_string + kernel_string1, arch=\"sm_\" + cc)\n",
        "calcgrad = mod.get_function(\"calcgrad\")\n",
        "print(\"Compiled calcgrad:\", calcgrad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Om28h7F9lK"
      },
      "source": [
        "## **Define \"Device code\" to solve time evolution equations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kssPZwGGLaZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d35a912-0c1e-4517-b0aa-e89fc254d6a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ],
      "source": [
        "from string import Template\n",
        "\n",
        "def get_kernel_string2_nd(nx, ny, dx, dy, dt, tau, kappa, kappa1, kappa2):\n",
        "    tmpl = Template(r\"\"\"\n",
        "    #include <math.h>\n",
        "    #define nx     $nx\n",
        "    #define ny     $ny\n",
        "    #define dx     $dx\n",
        "    #define dy     $dy\n",
        "    #define dt     $dt\n",
        "    #define tau    $tau\n",
        "    #define kappa  $kappa\n",
        "    #define kappa1 $kappa1\n",
        "    #define kappa2 $kappa2\n",
        "    #define pi     3.141592653589793\n",
        "\n",
        "    __global__ void timeevol(\n",
        "        const double *phi,\n",
        "        const double *temp,\n",
        "        double       *phi_new,\n",
        "        double       *temp_new,\n",
        "        const double *ax,\n",
        "        const double *ay,\n",
        "        const double *a2,\n",
        "        const double *grad_phix,\n",
        "        const double *grad_phiy,\n",
        "        const double *lap_phi,\n",
        "        const double *lap_temp\n",
        "    ){\n",
        "        int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "        if(i >= nx || j >= ny) return;\n",
        "\n",
        "        int ip = (i + 1) % nx, im = (i - 1 + nx) % nx;\n",
        "        int jp = (j + 1) % ny, jm = (j - 1 + ny) % ny;\n",
        "\n",
        "        int idx    = j*nx + i;\n",
        "        int idx_ip = j*nx + ip, idx_im = j*nx + im;\n",
        "        int idx_jp = jp*nx + i, idx_jm = jm*nx + i;\n",
        "\n",
        "        // divergence of anisotropic flux D∇φ\n",
        "        double d_ay_dx = (ay[idx_ip] - ay[idx_im]) / (2.0 * dx);\n",
        "        double d_ax_dy = (ax[idx_jp] - ax[idx_jm]) / (2.0 * dy);\n",
        "        double d_a2_dx = (a2[idx_ip] - a2[idx_im]) / (2.0 * dx);\n",
        "        double d_a2_dy = (a2[idx_jp] - a2[idx_jm]) / (2.0 * dy);\n",
        "        double div_flux = d_ay_dx + d_ax_dy\n",
        "                        + a2[idx] * lap_phi[idx]\n",
        "                        + d_a2_dx * grad_phix[idx]\n",
        "                        + d_a2_dy * grad_phiy[idx];\n",
        "\n",
        "        // Allen–Cahn reaction term with proper undercooling\n",
        "        double xi     = phi[idx];\n",
        "        double deltaT = -temp[idx];               // ΔT = -θ′\n",
        "        double m      = (xi - 0.5)\n",
        "                      - (kappa1/pi) * atan(kappa2 * deltaT);\n",
        "        double source = xi * (1.0 - xi) * m;\n",
        "        double dxi_dt = (div_flux + source) / tau;\n",
        "        double phi_tmp = xi + dt * dxi_dt;\n",
        "        if(phi_tmp < 0.0)      phi_tmp = 0.0;\n",
        "        else if(phi_tmp > 1.0) phi_tmp = 1.0;\n",
        "        phi_new[idx] = phi_tmp;\n",
        "\n",
        "        // Temperature evolution: ∂θ′/∂t = κ ∇²θ′ + ∂φ/∂t\n",
        "        double dT_dt = kappa * lap_temp[idx] + dxi_dt;\n",
        "        double temp_tmp = temp[idx] + dt * dT_dt;\n",
        "        // clamp θ′ into [−1,0]\n",
        "        if(temp_tmp < -1.0)      temp_tmp = -1.0;\n",
        "        else if(temp_tmp >  0.0) temp_tmp =  0.0;\n",
        "        temp_new[idx] = temp_tmp;\n",
        "    }\n",
        "    \"\"\")\n",
        "    return tmpl.substitute(\n",
        "        nx=nx, ny=ny,\n",
        "        dx=f\"{dx:.6e}\", dy=f\"{dy:.6e}\",\n",
        "        dt=f\"{dt:.6e}\", tau=f\"{tau:.6e}\",\n",
        "        kappa=f\"{kappa:.6e}\",\n",
        "        kappa1=f\"{kappa1:.6e}\",\n",
        "        kappa2=f\"{kappa2:.6e}\"\n",
        "    )\n",
        "\n",
        "# Recompile your kernel:\n",
        "kernel_string2 = get_kernel_string2_nd(nx, ny, dx, dy, dt, tau, kappa, kappa1, kappa2)\n",
        "timeevol_mod   = SourceModule(block_size_string + kernel_string2, arch=\"sm_\" + cc)\n",
        "timeevol       = timeevol_mod.get_function(\"timeevol\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGydi8nGGSFv"
      },
      "source": [
        "## **Allocate device memory, data transfer, and execute device codes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwSkx1EbLcYo"
      },
      "outputs": [],
      "source": [
        "# ─── Cell 1: PyCUDA + context setup ───\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use autoinit so you never lose your context\n",
        "import pycuda.autoinit\n",
        "from pycuda import driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "from time import time\n",
        "\n",
        "# Query device once\n",
        "device = drv.Context.get_current().get_device()\n",
        "major, minor = device.compute_capability()\n",
        "cc = f\"{major}{minor}\"           # e.g. \"75\" → arch=\"sm_75\"\n",
        "\n",
        "# Shared CUDA launch configuration\n",
        "threads = (16, 16, 1)\n",
        "grid    = (nx // threads[0], ny // threads[1], 1)\n",
        "block_size_string = (\n",
        "    \"#define block_size_x 16\\n\"\n",
        "    \"#define block_size_y 16\\n\"\n",
        ")\n",
        "\n",
        "# Alias for explicit context sync if ever needed\n",
        "context = drv.Context.get_current()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 2: Compile kernels ───\n",
        "import numpy as np   # for pi, etc.\n",
        "\n",
        "pi = np.pi\n",
        "\n",
        "# Generate and compile calcgrad\n",
        "kernel_string1 = get_kernel_string1_nd(nx, ny, dx, dy, pi, zeta, aniso, angle0)\n",
        "calcgrad_mod   = SourceModule(block_size_string + kernel_string1, arch=\"sm_\" + cc)\n",
        "calcgrad       = calcgrad_mod.get_function(\"calcgrad\")\n",
        "\n",
        "# Generate and compile timeevol\n",
        "kernel_string2 = get_kernel_string2_nd(nx, ny, dx, dy, dt, tau, kappa, kappa1, kappa2)\n",
        "timeevol_mod   = SourceModule(block_size_string + kernel_string2, arch=\"sm_\" + cc)\n",
        "timeevol       = timeevol_mod.get_function(\"timeevol\")\n",
        "\n",
        "print(\"Kernels loaded:\", calcgrad, timeevol)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejnd7rVAKeF3",
        "outputId": "1401d4b7-7b0a-4b34-b0af-ea3c28ae7a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernels loaded: <pycuda._driver.Function object at 0x7abcc8e524c0> <pycuda._driver.Function object at 0x7abcc98d83c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3: Allocate + launch ───\n",
        "\n",
        "# 1) Allocate GPU buffers\n",
        "phi      = drv.mem_alloc(phi_host.nbytes)\n",
        "…\n",
        "a2       = drv.mem_alloc(a2_host.nbytes)\n",
        "\n",
        "# 2) Upload data\n",
        "drv.memcpy_htod(phi, phi_host)\n",
        "drv.memcpy_htod(temp, temp_host)\n",
        "\n",
        "# 3) Warm up & timing\n",
        "context.synchronize()\n",
        "start_evt.record()\n",
        "t0 = time()\n",
        "\n",
        "# … then your calcgrad/timeevol loop …\n",
        "\n",
        "# 11) End timing\n",
        "end_evt.record()\n",
        "context.synchronize()\n",
        "t1 = time()\n",
        "print(\"Elapsed (ms):\", (t1 - t0)*1000)\n"
      ],
      "metadata": {
        "id": "1ID-ba9FKjMU",
        "outputId": "00ff5861-945b-4e5e-f411-389126fa0fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '…' (U+2026) (ipython-input-45-361722956.py, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-45-361722956.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    …\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '…' (U+2026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T3kT9GwSbKW"
      },
      "outputs": [],
      "source": [
        "# --- Debug: check final field values ---\n",
        "print(\"φ′   min/max:\", phi_result.min(), phi_result.max())\n",
        "print(\"θ′   min/max:\", temp_result.min(), temp_result.max())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}