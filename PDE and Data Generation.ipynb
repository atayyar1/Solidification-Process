{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fac39e87",
   "metadata": {},
   "source": [
    "**PDE and Data Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f7cbc",
   "metadata": {},
   "source": [
    "**PDE Discretization FIPY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8223a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fipy_runner.py\n",
    "\n",
    "import numpy as np\n",
    "from fipy import Variable, CellVariable, Grid2D, TransientTerm, DiffusionTerm, ImplicitSourceTerm\n",
    "from fipy.tools import numerix\n",
    "import os\n",
    "\n",
    "def run_simulation(dT0=-0.5, c=0.02, N=6, theta_deg=22.5,\n",
    "                   steps=1000, save_every=25, save_dir=\"dataset\", run_id=\"000\",\n",
    "                   seed_radius=0.125, seed_type='circle'):\n",
    "\n",
    "    dx = dy = 0.025\n",
    "    nx = ny = 250\n",
    "    dt = 5e-4\n",
    "    alpha = 0.015\n",
    "    tau = 3e-4\n",
    "    kappa1 = 0.9\n",
    "    kappa2 = 20.\n",
    "\n",
    "    mesh = Grid2D(dx=dx, dy=dy, nx=nx, ny=ny)\n",
    "    phase = CellVariable(name='xi', mesh=mesh, hasOld=True)\n",
    "    dT = CellVariable(name='DeltaT', mesh=mesh, hasOld=True)\n",
    "\n",
    "    # Orientation\n",
    "    theta = np.deg2rad(theta_deg)\n",
    "    psi = theta + numerix.arctan2(phase.faceGrad[1], phase.faceGrad[0])\n",
    "    Phi = numerix.tan(N * psi / 2)\n",
    "    PhiSq = Phi**2\n",
    "    beta = (1. - PhiSq) / (1. + PhiSq)\n",
    "    DbetaDpsi = -N * 2 * Phi / (1 + PhiSq)\n",
    "\n",
    "    Ddia = (1. + c * beta)\n",
    "    Doff = c * DbetaDpsi\n",
    "    I0 = Variable(value=((1, 0), (0, 1)))\n",
    "    I1 = Variable(value=((0, -1), (1, 0)))\n",
    "    D = alpha**2 * (1. + c * beta) * (Ddia * I0 + Doff * I1)\n",
    "\n",
    "    heatEq = (TransientTerm() == DiffusionTerm(2.25) + (phase - phase.old) / dt)\n",
    "    phaseEq = (TransientTerm(tau) == DiffusionTerm(D)\n",
    "               + ImplicitSourceTerm((phase - 0.5 - kappa1 / numerix.pi * numerix.arctan(kappa2 * dT)) * (1 - phase)))\n",
    "\n",
    "    # Initial seed\n",
    "    x, y = mesh.cellCenters\n",
    "    C = (nx * dx / 2, ny * dy / 2)\n",
    "    if seed_type == 'circle':\n",
    "        mask = ((x - C[0])**2 + (y - C[1])**2) < seed_radius**2\n",
    "    elif seed_type == 'square':\n",
    "        mask = (np.abs(x - C[0]) < seed_radius) & (np.abs(y - C[1]) < seed_radius)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported seed_type: {seed_type}\")\n",
    "    phase.setValue(1., where=mask)\n",
    "    dT.setValue(dT0)\n",
    "\n",
    "    xi_series = []\n",
    "    dT_series = []\n",
    "\n",
    "    for i in range(steps):\n",
    "        phase.updateOld()\n",
    "        dT.updateOld()\n",
    "        phaseEq.solve(phase, dt=dt)\n",
    "        heatEq.solve(dT, dt=dt)\n",
    "\n",
    "        if i % save_every == 0:\n",
    "            xi_series.append(phase.value.reshape((ny, nx), order='F').copy())\n",
    "            dT_series.append(dT.value.reshape((ny, nx), order='F').copy())\n",
    "\n",
    "    xi_series = np.stack(xi_series)\n",
    "    dT_series = np.stack(dT_series)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    np.save(os.path.join(save_dir, f\"xi_series_{run_id}.npy\"), xi_series)\n",
    "    np.save(os.path.join(save_dir, f\"dT_series_{run_id}.npy\"), dT_series)\n",
    "    if steps%10==0:\n",
    "        print(steps)\n",
    "    return xi_series.shape, dT_series.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b948b73",
   "metadata": {},
   "source": [
    "**GENERATE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0904284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_dataset.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "from PDE_Model import run_simulation  # You must define this in a separate file (e.g., fipy_runner.py)\n",
    "\n",
    "# === Batch Generation Script ===\n",
    "def generate_dataset():\n",
    "    output_dir = \"dataset500\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    param_grid = {\n",
    "        \"dT0\": [-0.2, -0.4, -0.6, -0.8],\n",
    "        \"c\": [0.005, 0.02, 0.05],\n",
    "        \"N\": [4, 6, 8],\n",
    "        \"theta_deg\": [0, 15, 30, 45],\n",
    "        \"seed_radius\": [0.08, 0.1, 0.15]\n",
    "        # No \"seed_type\"\n",
    "    }\n",
    "\n",
    "\n",
    "    combinations = list(itertools.product(*param_grid.values()))\n",
    "    keys = list(param_grid.keys())\n",
    "    total_runs = len(combinations)\n",
    "\n",
    "    meta_log = []\n",
    "\n",
    "    for run_index, combo in enumerate(combinations):\n",
    "        params = dict(zip(keys, combo))\n",
    "        run_id = f\"{run_index:03d}\"\n",
    "\n",
    "        print(f\"\\n🔄 Running simulation {run_index + 1}/{total_runs} → ID: {run_id}\")\n",
    "        print(f\"    Parameters: {params}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        xi_shape, dT_shape = run_simulation(\n",
    "            **params,\n",
    "            save_dir=output_dir,\n",
    "            run_id=run_id\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"    ✅ Done in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        meta_entry = {\n",
    "            \"run_id\": run_id,\n",
    "            \"filename_xi\": f\"xi_series_{run_id}.npy\",\n",
    "            \"filename_dT\": f\"dT_series_{run_id}.npy\",\n",
    "            **params,\n",
    "            \"xi_shape\": xi_shape,\n",
    "            \"dT_shape\": dT_shape\n",
    "        }\n",
    "        meta_log.append(meta_entry)\n",
    "\n",
    "    with open(os.path.join(output_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(meta_log, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✅ Finished generating {len(meta_log)} simulations. Metadata saved to metadata.json\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018d8a0",
   "metadata": {},
   "source": [
    "**GENERATE DATA MULTIPLE CPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from multiprocessing import Pool\n",
    "from PDE_Model import run_simulation\n",
    "\n",
    "# Simulation parameters\n",
    "param_grid = {\n",
    "        \"dT0\": [-0.2, -0.4, -0.6, -0.8],\n",
    "        \"c\": [0.005, 0.02, 0.05],\n",
    "        \"N\": [4, 6, 8],\n",
    "        \"theta_deg\": [0, 15, 30, 45],\n",
    "        \"seed_radius\": [0.08, 0.1, 0.15]\n",
    "        # No \"seed_type\"\n",
    "    }\n",
    "combinations = list(itertools.product(*param_grid.values()))\n",
    "keys = list(param_grid.keys())\n",
    "\n",
    "output_dir = \"dataset\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def run_wrapper(args):\n",
    "    run_index, combo = args\n",
    "    params = dict(zip(keys, combo))\n",
    "    run_id = f\"{run_index:03d}\"\n",
    "    print(f\"[{run_id}] Running simulation: {params}\")\n",
    "\n",
    "    xi_shape, dT_shape = run_simulation(\n",
    "        **params,\n",
    "        save_dir=output_dir,\n",
    "        run_id=run_id\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"run_id\": run_id,\n",
    "        \"filename_xi\": f\"xi_series_{run_id}.npy\",\n",
    "        \"filename_dT\": f\"dT_series_{run_id}.npy\",\n",
    "        **params,\n",
    "        \"xi_shape\": xi_shape,\n",
    "        \"dT_shape\": dT_shape\n",
    "    }\n",
    "\n",
    "def generate_dataset_parallel():\n",
    "    print(f\"🧠 Starting parallel generation on {os.cpu_count()} cores...\")\n",
    "    with Pool() as pool:\n",
    "        meta_log = pool.map(run_wrapper, enumerate(combinations))\n",
    "\n",
    "    with open(os.path.join(output_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(meta_log, f, indent=2)\n",
    "\n",
    "    print(f\"\\n✅ Finished generating {len(meta_log)} simulations. Metadata saved to metadata.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_dataset_parallel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d441e",
   "metadata": {},
   "source": [
    "**METADATA BUILDER**: Directorty that associates each combinations of parameters with its images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e53b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "# === Configuration ===\n",
    "DATASET_DIR = r\"C:\\Users\\Ali\\Desktop\\798 Project\\dataset_500\\dataset\"\n",
    "SAVE_DIR = DATASET_DIR\n",
    "\n",
    "input_keys = [\"dT0\", \"c\", \"N\", \"theta_deg\", \"seed_radius\"]\n",
    "param_grid = {\n",
    "    \"dT0\": [-0.2, -0.4, -0.6, -0.8],\n",
    "    \"c\": [0.005, 0.02, 0.05],\n",
    "    \"N\": [4, 6, 8],\n",
    "    \"theta_deg\": [0, 15, 30, 45],\n",
    "    \"seed_radius\": [0.08, 0.1, 0.15]\n",
    "}\n",
    "\n",
    "# Build full combinations\n",
    "combinations = list(itertools.product(*param_grid.values()))\n",
    "\n",
    "# Find available xi_series_XXX.npy files\n",
    "existing_run_ids = set()\n",
    "for fname in os.listdir(DATASET_DIR):\n",
    "    if fname.startswith(\"xi_series_\") and fname.endswith(\".npy\"):\n",
    "        run_id = fname.split(\"_\")[-1].split(\".\")[0]\n",
    "        existing_run_ids.add(run_id)\n",
    "\n",
    "# Build metadata ONLY for existing run_ids\n",
    "metadata = []\n",
    "for run_id in existing_run_ids:\n",
    "    run_index = int(run_id)\n",
    "    if run_index < len(combinations):\n",
    "        combo = combinations[run_index]\n",
    "        entry = {\n",
    "            \"run_id\": run_id,\n",
    "            \"filename_xi\": f\"xi_series_{run_id}.npy\"\n",
    "        }\n",
    "        for key, value in zip(input_keys, combo):\n",
    "            entry[key] = value\n",
    "        metadata.append(entry)\n",
    "\n",
    "# Save metadata.json\n",
    "metadata_path = os.path.join(SAVE_DIR, \"metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✅ Rebuilt metadata.json with {len(metadata)} entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae20e83",
   "metadata": {},
   "source": [
    "**PLOTTING**: takes number of xi, gives the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import imageio.v2 as imageio  # Avoid deprecation warning\n",
    "\n",
    "# === Settings ===\n",
    "run_id = \"228\"\n",
    "xi_file = r\"C:\\Users\\Ali\\Desktop\\798 Project\\dataset500\\xi_series_228.npy\" # Fixed here\n",
    "output_video = f\"dendrite_{run_id}.mp4\"\n",
    "fps = 5  # Frames per second\n",
    "cmap = \"plasma\"  # Colormap\n",
    "temp_dir = \"temp_frames\"\n",
    "\n",
    "# === Load data ===\n",
    "xi_series = np.load(xi_file)  # shape: (T, Ny, Nx)\n",
    "\n",
    "# === Create folder for frames ===\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "frame_paths = []\n",
    "\n",
    "# === Generate frames ===\n",
    "print(\"Generating frames...\")\n",
    "for t, frame in enumerate(xi_series):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    cax = ax.imshow(frame, origin='lower', cmap=cmap)\n",
    "    ax.set_title(f\"Time Step {t}\")\n",
    "    plt.colorbar(cax)\n",
    "\n",
    "    frame_path = os.path.join(temp_dir, f\"frame_{t:03d}.png\")\n",
    "    plt.savefig(frame_path)\n",
    "    frame_paths.append(frame_path)\n",
    "    plt.close()\n",
    "\n",
    "# === Save as MP4 ===\n",
    "print(\"Saving MP4 video...\")\n",
    "frames = [imageio.imread(p) for p in frame_paths]\n",
    "imageio.mimsave(output_video, frames, fps=fps)\n",
    "\n",
    "# === Clean up ===\n",
    "for p in frame_paths:\n",
    "    os.remove(p)\n",
    "os.rmdir(temp_dir)\n",
    "\n",
    "print(f\"\\n✅ Saved video to: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392c8da",
   "metadata": {},
   "source": [
    "**PLotting2**: Takes parameters and gets the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "# === Configuration ===\n",
    "# Set your dataset directory path here\n",
    "DATASET_DIR = r\"C:\\Users\\Ali\\Desktop\\798 Project\\dataset\"\n",
    "\n",
    "# Choose the parameters to match\n",
    "target_params = {\n",
    "    \"dT0\": -0.6,\n",
    "    \"c\": 0.02,\n",
    "    \"N\": 6,\n",
    "    \"theta_deg\": 30,\n",
    "    \"seed_radius\": 0.1\n",
    "}\n",
    "\n",
    "# === Load metadata and find matching run ===\n",
    "metadata_path = os.path.join(DATASET_DIR, \"metadata.json\")\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "def is_close(a, b, tol=1e-6):\n",
    "    return abs(a - b) < tol if isinstance(a, float) else a == b\n",
    "\n",
    "match = None\n",
    "for entry in metadata:\n",
    "    if all(is_close(entry.get(k), v) for k, v in target_params.items()):\n",
    "        match = entry\n",
    "        break\n",
    "\n",
    "if match is None:\n",
    "    print(\"❌ No matching simulation found for the specified parameters.\")\n",
    "else:\n",
    "    run_id = match[\"run_id\"]\n",
    "    xi_file = os.path.join(DATASET_DIR, match[\"filename_xi\"])\n",
    "    print(f\"✅ Found match: Run ID {run_id}, loading {xi_file}\")\n",
    "\n",
    "    # === Load data and plot frames ===\n",
    "    xi_series = np.load(xi_file)\n",
    "    video_path = os.path.join(DATASET_DIR, f\"dendrite_{run_id}.gif\")\n",
    "\n",
    "    frames = []\n",
    "    for t, frame in enumerate(xi_series):\n",
    "        fig, ax = plt.subplots(figsize=(8, 8), dpi=150)\n",
    "        cax = ax.imshow(frame, cmap=\"plasma\", origin=\"lower\", vmin=0, vmax=1, interpolation=\"bilinear\")\n",
    "        ax.set_title(f\"Dendritic Growth: t={t}\", fontsize=10)\n",
    "        fig.colorbar(cax)\n",
    "        frame_path = os.path.join(DATASET_DIR, f\"_temp_frame_{t}.png\")\n",
    "        plt.savefig(frame_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig)\n",
    "        image = Image.open(frame_path).convert(\"RGB\")\n",
    "        frames.append(image)\n",
    "\n",
    "    # Resize all frames to the same shape using PIL\n",
    "    min_shape = min((img.size for img in frames), key=lambda x: x[0]*x[1])\n",
    "    frames = [img.resize(min_shape, Image.Resampling.LANCZOS) for img in frames]\n",
    "\n",
    "    frames[0].save(video_path, save_all=True, append_images=frames[1:], duration=200, loop=0)\n",
    "\n",
    "    for t in range(len(xi_series)):\n",
    "        os.remove(os.path.join(DATASET_DIR, f\"_temp_frame_{t}.png\"))\n",
    "\n",
    "    print(f\"🎥 Video saved to: {video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
